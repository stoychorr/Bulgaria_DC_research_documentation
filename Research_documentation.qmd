---
title: "The Impact of Demographic Changes on Economic Growth in Bulgaria (Research documentation)"
author: "Stoycho Rusinov"
format: html
editor: visual
---

## Abstract

This study examines the demographic crisis in Bulgaria as a critical barrier to economic growth. By analyzing data from the past century, based on the Bulgarian Statistical Yearbook, we investigate the impact of demographic changes on Gross Domestic Product (GDP), capital, and its efficiency. An econometric evaluation of the factors influencing GDP is conducted using data spanning a broad time range to highlight the economic processes that have stimulated growth across three different political regimes in Bulgaria's history.

The results indicate that, until the end of the socialist period, demographic growth was not the primary driver of economic progress due to the inefficient utilization of labor resources. However, following the transition, human capital began to play a decisive role in GDP dynamics, surpassing even gross capital investments. This shift raises a critical question: Can the declining population slow GDP growth to the extent that it triggers a recession and transforms the demographic crisis into a significant macroeconomic problem?

# Bulgaria after 1989 (Modern Bulgaria)

Prepare the data from excel:

```{r}
options(warn=-1)
library(readxl)
data_stop_isty <- read_excel("data stop isty.xlsx", 
    col_types = c("text", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "numeric", "numeric"))
head(data_stop_isty)
```

Provide descriptive statistics of the data:

```{r}
psych::describe(data_stop_isty)
```

Fit the model:

$$
\Delta Z'_t = \alpha_0 + \alpha_1 \cdot \frac{\Delta \text{Compensation}_t}{\text{Compensation}_{t-1}} + \alpha_2 \cdot \Delta Z_t + \alpha_3 \cdot \frac{\text{Fixed\_Capital}_t}{\text{Fixed\_Capital}_{t-1}} +\text{shock1}_t+\text{shock2}_t+ \varepsilon_t
$$

where $\Delta Z_t=\frac{\Delta \mathrm{Hired}_t}{\mathrm{Hired}_{t-1}}-\frac{\Delta \mathrm{Hired}_{t-4}}{\mathrm{Hired}_{t-5}}$ и $\Delta Z'_t=\frac{\Delta \mathrm{GDP}_t}{\mathrm{GDP}_{t-1}}-\frac{\Delta \mathrm{GDP}_{t-4}}{\mathrm{GDP}_{t-5}}$, which we perform to remove the temporal and cyclic dependencies in the data.

```{r}
# Load necessary library
library(dplyr)
library(stargazer)
# Create the differenced variable with NA padding for alignment
data_stop_isty$diff_Hired_lag4 <- c(rep(NA, 4), diff(data_stop_isty$Hired, lag = 4))
data_stop_isty$diff_GDP <- c(rep(NA, 4), diff(data_stop_isty$GDP, lag = 4))
#Load the main OLS model
time<-array()
i<-0
while (i<=110){
  if (i<=19){
    time[i]<-1
  } else {time[i]=0}
  i<-i+1
}
time2<-array()
i <- 0
while (i <= 110) {
  if (i > 55 && i < 60) {
    time2[i] <- 1
  } else {
    time2[i] <- 0
  }
  i <- i + 1
}
model1_nohetero<-lm(diff_GDP~Compensation_of_Employees+Consumption_of_Fixed_Capital+diff_Hired_lag4, data=data_stop_isty[,-c(1,4,5,6,9)])
model1_hetero<-lm(diff_GDP~Compensation_of_Employees+Consumption_of_Fixed_Capital+diff_Hired_lag4+time+time2, data=data_stop_isty[,-c(1,4,5,6,9)])
library(sandwich)
robust_se <- vcovHC(model1_hetero, type = "HC")
# Use robust standard errors in model summaries
library(lmtest)
coeftest(model1_hetero, vcov = robust_se)
```

The graph of the differenced GDP is:

```{r}
options(warn=-1)
plot(seq(1:110),data_stop_isty$diff_GDP, type="l", main="Изменения на диференцираното БВП с два и четири лагови стойности.", xlab="Период в тримесечия", ylab="Изменения в БВП")
```

Perform ADF tests on the all variables to insure they fit the requirements of the Granger test and linear regression modelling (so are statinary):

```{r}
suppressWarnings({
library(tseries)

columns_to_test <- c("Compensation_of_Employees", "Consumption_of_Fixed_Capital", "diff_Hired_lag4")

adf_results <- list()

for (col in columns_to_test) {
  data_to_test <- na.omit(data_stop_isty[[col]])
  adf_results[[col]] <- adf.test(data_to_test)
}

# Extract ADF statistic, p-value, and other results
for (col in columns_to_test) {
  cat("Results for:", col, "\n")
  cat("ADF Test Statistic:", adf_results[[col]]$statistic, "\n")
  cat("P-value:", adf_results[[col]]$p.value, "\n")
  cat("Alternative Hypothesis:", adf_results[[col]]$alternative, "\n")
  cat("-----------------------------\n")
}

rm(data_to_test)
})
```

Due to the low $R^2$ we will perform the RESET test to check for omitted variables:

```{r}
suppressMessages({
library(lmtest)
resettest(model1_nohetero, power=2:3)})
```

Perform tests for heteroscedasticity, and DW test on residuals to insure they fit the axioms of linear regression and then print the auto correlation table:

```{r}
options(warn=-1)
library(lmtest)
dwtest(model1_nohetero)
bptest(model1_nohetero, studentize = TRUE)
acf(model1_hetero$residuals, main="Автокорелограма на остатъчните грешки в линейната регресия")
```

No autocorrelation was detected, as evidenced by the autocorrelation table, which shows that the structure of the lagged error terms is adequate for further reliability assurance. However, due to the model's low predictive power, the Breusch-Pagan (BP) test suggests the presence of heteroscedasticity in the error terms, which is expected. To meet the package requirements for other regression models, we need to adjust the lengths of the dummy variables accordinglly, we do this by utilizing a while woop, to construct a dummy variable:

```{r}
rm(time)
rm(time2)
time<-array()
time2<-array()
i=0
while (i<=106){
  if (i<=19){
    time[i]=1
  } else {time[i]=0}
  i=i+1
}
time2<-array()
i <- 1
while (i <= 106) {
  if (i > 55 && i < 60) {
    time2[i] <- 1
  } else {
    time2[i] <- 0
  }
  i <- i + 1
}
```

Fit robust regression model for comparison:

```{r}
options(warn=-1)
library(MASS)
data_stop_isty<-na.omit(data_stop_isty[,-c(1,4,5,6,9)])
# Fit the robust regression model
robust_model <- rlm(diff_GDP~Compensation_of_Employees+Consumption_of_Fixed_Capital+diff_Hired_lag4, data=data_stop_isty, method="M")
robust_model2 <- rlm(diff_GDP~Compensation_of_Employees+Consumption_of_Fixed_Capital+diff_Hired_lag4, data=data_stop_isty, method="MM")
predicted_values_RM <- predict(robust_model, newdata = na.omit(data_stop_isty[, -c(1, 4, 5, 6, 9)]))
predicted_values_RM2 <- predict(robust_model2, newdata = na.omit(data_stop_isty[, -c(1, 4, 5, 6, 9)]))
SST <- sum((data_stop_isty$diff_GDP - mean(data_stop_isty$diff_GDP))^2)
SSE <- sum((data_stop_isty$diff_GDP - predicted_values_RM)^2)
r_squared <- 1 - (SSE / SST)
print(paste("R_ squared=",round(r_squared,2)))
SSE <- sum((data_stop_isty$diff_GDP - predicted_values_RM2)^2)
r_squared <- 1 - (SSE / SST)
print(paste("R_ squared=",round(r_squared,2)))
stargazer::stargazer(robust_model, robust_model2, type="text")
```

Perform the BP-test for heteroscedasticity:

```{r}
lmtest::bptest(robust_model)
```

Fit a general linear model to use the maximum likelihood estimator instead of OLS for comparison.

```{r}

options(warn = -1)
library(dplyr)
library(stargazer)

# Fit the model using glmmTMB
model_general_lenear <- glm(diff_GDP ~ Compensation_of_Employees + Consumption_of_Fixed_Capital + diff_Hired_lag4 , 
                                data = data_stop_isty, family = gaussian())

predicted_values_GLM <- predict(model_general_lenear, newdata = na.omit(data_stop_isty[, -c(1, 4, 5, 6, 9)]))

#calculate r squared manually and then print the result

SST <- sum((data_stop_isty$diff_GDP - mean(data_stop_isty$diff_GDP))^2)
SSE <- sum((data_stop_isty$diff_GDP - predicted_values_GLM)^2)
r_squared <- 1 - (SSE / SST)
print(paste0("R squared is = ", round(r_squared, digits = 2)))
stargazer::stargazer(model_general_lenear, type="text")
AIC(model_general_lenear)
```

We will perform tests for heteroscedasticity and autocorrelation of the residuals for the glm to access the reliability of this model:

```{r}
bptest(model_general_lenear)
dwtest(model_general_lenear)
shapiro.test(model_general_lenear$residuals)
```

Based on the QQ plot, the residuals of the model appear to be approximately normal with the exception of some slight deviations in the tails of the distribution:

```{r}
qqnorm(model_general_lenear$residuals)
qqline(model_general_lenear$residuals, col = "blue")
```

Since the pseudo r-squared is quite low in the gaussian model and the robust model, we can perform the Generalized additive model, with splain functions of the following type: $$
S(x) = 
\begin{cases} 
a_1 + b_1(x - x_1) + c_1(x - x_1)^2 + d_1(x - x_1)^3 & \text{for } x_1 \leq x < x_2 \\
a_2 + b_2(x - x_2) + c_2(x - x_2)^2 + d_2(x - x_2)^3 & \text{for } x_2 \leq x < x_3 \\
\vdots \\
a_n + b_n(x - x_n) + c_n(x - x_n)^2 + d_n(x - x_n)^3 & \text{for } x_{n-1} \leq x \leq x_n
\end{cases}
$$ To determine whether there are significant non-linear realtionships in the data, that are measured with "wigly" curves. The general form of GAM with splain is given by: $$
S(x)=\sum_{i=1}^N\alpha_i\phi_i(x)
$$ Where $\alpha_i$ are the coefficients of the spline and $\phi_i$ are the basis functions. The approximation of such model will insure that the non-linear relationships in the, if any, are adequately captured by the model. The leftover unexplained variance will be attributed to factors outside the scope of this approximation.

```{r fig.height=20, fig.width=20}
# Load the package
library(mgcv)

# Generalized Additive Model
model_gam <- gam(diff_GDP ~ s(Compensation_of_Employees) + 
                           s(Consumption_of_Fixed_Capital) + 
                           s(diff_Hired_lag4), 
                 data = data_stop_isty, family = gaussian())
summary(model_gam)

plot(model_gam, pages = 1)
AIC(model_gam)
```

We provide a plot of the components of this gamma model:

```{r}
plot(model_gam)
```

Now, we will derive the relative deviance explained by each parameter in the GAM model:

```{r}
compensation<- gam(diff_GDP ~ s(Compensation_of_Employees), 
                 data = data_stop_isty, family = gaussian())
employees<-gam(diff_GDP ~ s(diff_Hired_lag4), 
                 data = data_stop_isty, family = gaussian())
capital<-gam(diff_GDP ~ s(Consumption_of_Fixed_Capital), 
                 data = data_stop_isty, family = gaussian())
cat("Deviance explained by the relative change in employed compensation:", summary(compensation)$dev.expl,"\n")
cat("Deviance explained by relative change in employed:",summary(employees)$dev.expl, "\n")
cat("Deviance explained by relative change in employed:",summary(capital)$dev.expl, "\n")
#Create a vector of fitted values for this model to compare with the real data
predicted_values_GAM<-model_gam$fitted.values
```

From we can easily observe that the relative change of the employed persons explaines higher percentage of the deviance in GDP.

```{r}
# Create a plot for predicted values
plot(
  predicted_values_GAM, 
  type = "l", 
  col = "blue", 
  xlab = "Месеци след 1995 година", 
  ylab = "Отн. изменения", 
  main = "Прогнозирани vs. реални стойности в измененията на БВП"
)
# Add the actual values to the same plot
lines(
  data_stop_isty$diff_GDP, 
  col = "black"
)


# Add a legend to differentiate between predicted and actual values
legend(
  "topright", 
  legend = c("Прогноза (GAM)", "Реални стойности"), 
  col = c("blue", "black"), 
  lty = 1
)

```

Upon the statistical realization of the second mentioned in the beggining of the research paper we will mention the augmented Solow model, by beginning with the initial definition of the production function in the main Solow model: $$
Y=A\cdot F(K,Z\cdot N)
$$ Where $N$ is the number of workers employed in the economy and Z is their productivity. $K$ represents the capital accumulation. Except for the technological progress every other parameter in the above equation is defined in a series of equatins: $$
K_t=I_t+(1-\delta)\cdot K_{t-1},
$$ $$
𝑁_𝑡=(1+𝑛)\cdot 𝑁_{𝑡−1},
$$ $$
𝑍_𝑡=(1+𝜔) \cdot 𝑍_{𝑡−1}
$$ In this model, the parameter \$ \omega \$ denotes the rate of improvement in labor productivity over time. The model posits that technological progress is continuously advancing, thereby amplifying the impact of the population parameter on GDP development. Specifically, \$ \omega \$ captures the rate at which labor productivity enhances, reflecting ongoing technological advancements.The parameter \$ n \$ represents the rate of population growth. While \$ n \$ typically increases, it is projected to decline in Bulgaria due to the ongoing demographic crisis. This demographic shift alters the conventional expectations regarding population dynamics and their influence on GDP growth. For the purposes of this approximation we will assume that the combined term $(1+𝜔)(1+𝑛)\cdot 𝑍_{𝑡−1}𝑁_{𝑡−1}$ is identically equal to the working population (employed + self-employed). We as well assume that the quantity $K_t=I_t+(1-\delta)\cdot K_{t-1}$ is equal to the "brute capital investments" as refered to by the National Statics institute.From here we have the following form of the equation: $$
Y(K_t,L_t)=AK_t^\alpha L_t^\beta
$$ The log form of the equation above is given by: $$
\ln (Y_t)=\ln(A)+\alpha\cdot\ln(K_t)+\beta\cdot\ln(L_t)
$$ Given the model specification, there may be issues related to the potential lack of stationarity and the presence of autocorrelation in the residuals of the regression model. To address these concerns, it is essential to examine whether the time series data for the variables in the model exhibit non-stationary behavior or if the residuals are auto-correlated.

Non-stationarity can lead to unreliable estimates and misleading inferences, while autocorrelation in residuals can indicate that the model does not fully capture the dynamics of the data.

To correct for these issues, we can apply the disintegration method. This approach involves transforming the variables to obtain their relative changes, which helps to mitigate problems associated with non-stationarity and autocorrelation. By focusing on the relative changes, we can enhance the robustness of the regression analysis and obtain more reliable estimates.To do this take the difference $\Delta$ on both sides of the last equation: $$
\Delta \underbrace{\ln (Y_t)}_{\ln\left(\frac{Y_t}{Y_{t-1}}\right)} = \ln(A)-\ln(A)+\alpha\cdot (\underbrace{\ln(K_t)-\ln(K_{t-1})}_{\ln\left(\frac{K_t}{K_{t-1}}\right)})+\beta\cdot(\underbrace{\ln(L_t)-\ln(L_{t-1})}_{\ln\left(\frac{L_t}{L_{t-1}}\right)})
$$ To begin with the statistical analysis we first import the data:

```{r}
library(readxl)
Second_model_data <- read_excel("Second_model_data.xlsx")
head(Second_model_data)
```

Now, we perform the necessary transformations of the variables to reach the form of the last equation:

```{r}
suppressWarnings({
GDP<-log(as.numeric(Second_model_data $GDP)/as.numeric(lag(Second_model_data $GDP)))
Capital<-log(Second_model_data$Capital_accumulation/lag(Second_model_data $Capital_accumulation))
Labor<-log(Second_model_data $active/lag(Second_model_data $active))
df<-data.frame(
  "GDP"=GDP,
  "Capital"=Capital,
  "Labor"=Labor
)
df<-na.omit(df)
})
```

Based on the newly acquired data we can now perform the OLS estimation:

```{r}
model_CD<-lm(GDP~Capital+Labor, data=df)
stargazer::stargazer(model_CD, type="text")
```

We need to perform some additional test to insure the reliability of the data, mainly stationarity tests and tests for autocorrelation:

```{r}
#ADF tests:
library(lmtest)
test.1<-adf.test(na.omit(df$GDP),k=3)
test.2<-adf.test(na.omit(df$Capital), k=1)
test.3<-adf.test(na.omit(df$Labor),k=3)

cat(sprintf("1. GDP\n"))
cat(sprintf("   - Dickey-Fuller Statistic: %.4f\n", test.1$statistic))
cat(sprintf("   - p-value: %.4f\n", test.1$p.value))
cat(sprintf("   - Number of Lags: %d\n", test.1$parameter))
cat(sprintf("   - Alternative Hypothesis: %s\n\n", test.1$alternative))
cat(rep("-",15),"\n")
cat(sprintf("2. Capital\n"))
cat(sprintf("   - Dickey-Fuller Statistic: %.4f\n", test.2$statistic))
cat(sprintf("   - p-value: %.4f\n", test.2$p.value))
cat(sprintf("   - Number of Lags: %d\n", test.2$parameter))
cat(sprintf("   - Alternative Hypothesis: %s\n\n", test.2$alternative))
cat(rep("-",15),"\n")
cat(sprintf("3. Labor\n"))
cat(sprintf(" - Dickey-Fuller Statistic: %.4f\n", test.3$statistic))
cat(sprintf(" - p-value: %.4f\n", test.3$p.value))
cat(sprintf(" - Number of Lags: %d\n", test.3$parameter))
cat(sprintf(" - Alternative Hypothesis: %s\n\n", test.3$alternative))
```

The results however point towards the idea that the series are not stationary in the 95% confidence interval, however all of them appear to be stationary in the 90% confidence interval. Regardless of the discovered lack of stationarity the final model appears to be reasonable and except the heteroscedasticity no correlation had been discovered. GDP appears to be highly correlated with both variables but the variables themselves are not correlated, ruling out the possibility of multicolinearity. The tests are given here:

```{r}
library(lmtest)
bptest(model_CD)
dwtest(model_CD)
car::vif(model_CD)
shapiro.test(residuals(model_CD))

```

The test detects possible hetersocedasticity but the residuals appear to be normally distributed and not autocorrelated. Heteroscedasticity causes most problems in the estimation of standard errors, so we will provide standard errors that account for heteroscedastic behavior by estimating the variance-covariance matrix, that is given below:

$$
\text{Var}(\hat{\boldsymbol{\beta}}) = (\mathbf{X}^\top \mathbf{X})^{-1} \left( \mathbf{X}^\top \mathbf{\Omega} \mathbf{X} \right) (\mathbf{X}^\top \mathbf{X})^{-1}
$$ where:

-   $\mathbf{X}$ is the matrix of independent variables.
-   $\mathbf{\Omega}$ is a diagonal matrix with the squared residuals as its diagonal elements, representing heteroscedasticity.
-   $\hat{\boldsymbol{\beta}}$ is the vector of OLS estimates.
-   $\text{Var}(\hat{\boldsymbol{\beta}})$ is the heteroscedasticity-consistent covariance matrix of $\hat{\boldsymbol{\beta}}$.

The procedure is readily given below and the standard errors as well as p-values estimated:

```{r}
# Calculate heteroscedasticity-consistent standard errors (Huber-White)
library(sandwich)
robust_se <- vcovHC(model_CD, type = "HC")
# Use robust standard errors in model summaries
library(lmtest)
coeftest(model_CD, vcov = robust_se)
```

As seen from the table above all variables appear to still be statistically significant.

```{r}
stargazer::stargazer(model1_nohetero,
model1_hetero,
model_CD,robust_model, type="text")

```

Test for multicolinearity:

```{r}
library(car)
cat("model 1: ", vif(model1_nohetero), "\n")
cat("model 2: ", vif(model_CD),"\n")
cat("model 3: ", vif(robust_model),"\n")
cat("model 4: ", vif(model1_hetero),"\n")
```

# Bulgaria in the period between 1888 and 1947 (Kingdom of Bulgaria)

The data has already been prepared in excel, so we just export it from the relative directory:

```{r message=FALSE, warning=FALSE}

library(readxl)
data <- read_excel("data.xlsx")
head(data)

```

We will perform the procedure of differencing with one lag on every variable in our data, following the formula:

$$
\Delta_{\text{lag=1}}X_t=\frac{X_{t}-X_{t-1}}{X_{t-1}}
$$

Before that we perform some initial cleaning of the excel spreadsheet, to remove any redundant excel object that is not recognized by R:

```{r}
colnames(data)[4]<-"GDP"
data<-data[,c(seq(1:4))]
#after the clean up we produce a correlation plot to visualize time dependencies:
psych::cor.plot(data)

```


```{r}

library(dplyr)

# Ensure all relevant columns are numeric and clean potential non-numeric values
data <- data %>%
  mutate(
    GDP = as.numeric(as.character(GDP)),
    Born_alive = as.numeric(as.character(Born_alive)),
    Population = as.numeric(as.character(Population))
  )

# Calculate growth rates and handle NAs where appropriate
new_data <- data %>%
  mutate(
    GDP_growth = (GDP - lag(GDP)) / lag(GDP),
    Birth_rate_growth = (Born_alive - lag(Born_alive)) / lag(Born_alive),
    Birth_rate = Born_alive,
    Population_growth = (Population - lag(Population)) / lag(Population)
  ) 
new_data<-new_data[,-c(2,3,4)]
new_data[is.na(new_data)] <- 0
print(new_data)



psych::cor.plot(new_data) 

```


```{r}
# Perform the ADF tests
library(tseries)
adf_gdp <- adf.test(new_data$GDP_growth)
adf_pop <- adf.test(new_data$Population_growth,k=3)
adf_birth <- adf.test(new_data$Birth_rate_growth,k=1)
adf_birth2 <- adf.test(new_data$Birth_rate)
print(adf_gdp)
print(adf_pop)
print(adf_birth)
print(adf_birth2)
```

Further evidence for the stationary character of the processes is given by the autocorrelation plots:

```{r}
acf(new_data$GDP_growth)
acf(new_data$Birth_rate_growth)
acf(new_data$Population_growth)
acf(new_data$Birth_rate)
pacf(new_data$GDP_growth)
pacf(new_data$Birth_rate_growth)
pacf(new_data$Population_growth)
pacf(new_data$Birth_rate)
```

From where we can easily observe that only one difference was enough to insure the removal of any non-stationary process. This procedure allows us to asses the connections between GDP and the population growth by utilizing a correlation matrix:

From the correlation plot we observe a very small correlation between the population change (partially due to the approximation algorithms used by the national statistics institute). Now we will create dummy variable to account for the wars and economic crisis that Bulgaria have been facing during the period between 1888 to 1947:

```{r}
i <- 0
wars<-array()
while (i < 57) {
  if (i > 21 && i < 25) {
    wars[i]<-1
  }
  if (i > 24 && i < 30) {
    wars[i]<-1
  }
  if (i > 49 && i < 56) {
    wars[i]<-1
  } else wars[i]=0
  i = i + 1
}
new_data$wars<-wars
```

Lets recreate the correlation table with our new variable:

```{r fig.height=10, fig.width=20}
suppressWarnings({
library(psych)
corPlot(new_data, main="Корелограма на взаимовръзката между войните, БВП и населението")
})
```

```{r}
library(lmtest)
grangertest(new_data$GDP_growth~new_data$Birth_rate_growth, order=6)
grangertest(new_data$GDP_growth~new_data$Population_growth, order=8)
```

```{r}
lagged_data <- new_data %>%
  mutate(
    G=GDP_growth,
    G1 = lag(GDP_growth, 1),
    G2 = lag(GDP_growth, 2),
    G3 = lag(GDP_growth, 3),
    G4 = lag(GDP_growth, 4),
    G5 = lag(GDP_growth, 5),
    G6 = lag(GDP_growth, 6),
    G7 = lag(GDP_growth, 7),
    
    B1 = lag(Birth_rate_growth, 1),
    B2 = lag(Birth_rate_growth, 2),
    B3 = lag(Birth_rate_growth, 3),
    B4 = lag(Birth_rate_growth, 4),
    B5 = lag(Birth_rate_growth, 5),
    B6 = lag(Birth_rate_growth, 6),
    B7 = lag(Birth_rate_growth, 7),
    
    P1 = lag(Population_growth, 1),
    P2 = lag(Population_growth, 2),
    P3 = lag(Population_growth, 3),
    P4 = lag(Population_growth, 4),
    P5 = lag(Population_growth, 5),
    P6 = lag(Population_growth, 6),
    P7 = lag(Population_growth, 7)
  )
lagged_data<-lagged_data[,-c(1,2,3,4,5,6)]
psych::cor.plot(lagged_data)
```

# Bulgaria in the period between 1945 and 1989 (the socialists regime)

First export the data from excel and visualize the head to insure adequacy:

```{r}
library(readxl)
data <- read_excel("data.xlsx", sheet = "1944-1989")
head(data)
```

Now we will create a separate data frame containing only the relevant parameters and clean the data:

```{r}
Data<-data[,c(1,2,3,4,5,6,7)]
psych::describe(Data)
library(dplyr)
Data <- Data %>%
  mutate(
    capital_diff = (Capital_investments - lag(Capital_investments)) / lag(Capital_investments),
    Population_diff=(Population-lag(Population))/lag(Population),
    All_employed_diff=(All_employed-lag(All_employed))/lag(All_employed),
    Workers_diff=(Workers-lag(Workers))/lag(Workers),
    GSP_diff=(GSP-lag(GSP))/lag(GSP),
    GNP_diff=(GNP-lag(GNP))/lag(GNP),
  )

```

```{r}
Data<-na.omit(Data[,-c(1,2,3,4,5,6,7)])
psych::cor.plot(Data)
```

```{r}


```

```{r}
library(tseries)
library(dplyr)
library(kableExtra)
perform_adf_test <- function(series_name, series_data) {
  if (length(na.omit(series_data)) == 0) {
    message(paste("Warning: No valid data for series", series_name))
    return(data.frame(Series = series_name, p_value = NA, Statistic = NA))
  }
  
  result <- tryCatch(adf.test(series_data), error = function(e) {
    message(paste("Error running ADF test for series", series_name, ":", e$message))
    return(NULL)
  })
  if (is.null(result)) {
    return(data.frame(Series = series_name, p_value = NA, Statistic = NA))
  }
  critical_values <- ifelse(!is.null(result$critical.values), result$critical.values, rep(NA, 3))
  
  return(data.frame(
    Series = series_name,
    p_value = result$p.value,
    Statistic = result$statistic
  ))
}

series_list <- c("Capital Diff", "All Employed Diff", "Workers Diff", "Population Diff", "GSP Diff", "GNP Diff")
data_list <- list(Data$capital_diff, Data$All_employed_diff, Data$Workers_diff, Data$Population_diff, Data$GSP_diff, Data$GNP_diff)
adf_results <- bind_rows(mapply(perform_adf_test, series_list, data_list, SIMPLIFY = FALSE))
adf<-data.frame(
  Series=adf_results$Series,
  p_value=adf_results$p_value,
  Statistic=adf_results$Statistic
)
print(adf)
```

```{r}
# Load necessary library
library(lmtest)

tests <- list(
  list(dep_var = "GNP_diff", ind_var = "capital_diff", order = 1),
  list(dep_var = "GSP_diff", ind_var = "capital_diff", order = 3),
  list(dep_var = "GNP_diff", ind_var = "Workers_diff", order = 1),
  list(dep_var = "GSP_diff", ind_var = "Workers_diff", order = 1),
  list(dep_var = "GNP_diff", ind_var = "Population_diff", order = 5),
  list(dep_var = "GSP_diff", ind_var = "Population_diff", order = 5),
  list(dep_var = "GNP_diff", ind_var = "All_employed_diff", order = 1),
  list(dep_var = "GSP_diff", ind_var = "All_employed_diff", order = 1)
)

results <- data.frame(Test_No = integer(),
                      Dependent_Variable = character(),
                      Independent_Variable = character(),
                      Order = integer(),
                      F_Statistic = numeric(),
                      P_Value = numeric(),
                      stringsAsFactors = FALSE)

for (i in seq_along(tests)) {
  test <- tests[[i]]
  result <- na.omit(grangertest(as.formula(paste(test$dep_var, "~", test$ind_var)), order = test$order, data = Data))
  if (!is.null(result)) {
    f_stat <- result$F[1]
    p_val <- result$`Pr(>F)`[1]
  } else {
    f_stat <- NA
    p_val <- NA
  }
  results <- rbind(results, data.frame(Test_No = i,
                                        Dependent_Variable = test$dep_var,
                                        Independent_Variable = test$ind_var,
                                        Order = test$order,
                                        F_Statistic = f_stat,
                                        P_Value = p_val))
}

print(results)


```

```{r}
# Load necessary libraries
library(ivreg)
library(stargazer)
library(car)
library(lmtest)
library(sandwich)

# Linear regression model
model <- lm(GSP_diff ~ capital_diff + lag(Population_diff, 7) + Workers_diff, data = Data)

# Instrumental variables (IV) regression model
modeliv <- ivreg(GSP_diff ~ Workers_diff | lag(Population_diff, 7), data = Data)

# Summary of both models with stargazer
stargazer::stargazer(model, modeliv, type = "text")

# Variance Inflation Factor (VIF) for multicollinearity in the linear model
vif(model)

# Breusch-Pagan test for heteroscedasticity in both models
bptest(model)    # For the linear model
bptest(modeliv)  # For the IV model

# Breusch-Godfrey test for serial correlation in both models
bgtest(model)    # For the linear model
bgtest(modeliv)  # For the IV model

# Shapiro-Wilk test for normality of residuals in both models
shapiro.test(model$residuals)    # For the linear model
shapiro.test(modeliv$residuals)  # For the IV model

# Partial Autocorrelation Function (PACF) of residuals in both models
pacf(model$residuals)    # For the linear model
pacf(modeliv$residuals)  # For the IV model

# Robust standard errors using heteroscedasticity-consistent (HC1) covariance matrix in the IV model
coeftest(modeliv, vcov = vcovHC(modeliv, type = "HC1"))

```
